{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_SMC.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMzUgv3ULbuUnHWpsaab6ad",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabrielvinicios02/ExperimentsMultivariate/blob/main/LSTM_SMC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8fg6834nWYXi"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/python\n",
        "# -*- coding: utf-8 -*-\n",
        "# Script to forecast variable using multivariate LSTM\n",
        "\n",
        "from pandas import DataFrame\n",
        "from pandas import read_csv\n",
        "from pandas import concat\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from math import sqrt\n",
        "from matplotlib import pyplot\n",
        "from numpy import concatenate\n",
        "from numpy import diff\n",
        "import numpy\n",
        "import pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "# To get reproducible results with Keras\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "#from tensorflow import set_random_seed\n",
        "#set_random_seed(2)\n",
        "tensorflow.compat.v1.set_random_seed(2)"
      ],
      "metadata": {
        "id": "Mxp7L8ArWb9J"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert series to supervised learning\n",
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "\t\"\"\"\n",
        "\tFrame a time series as a supervised learning dataset.\n",
        "\tArguments:\n",
        "\t\tdata: Sequence of observations as a list or NumPy array.\n",
        "\t\tn_in: Number of lag observations as input (X).\n",
        "\t\tn_out: Number of observations as output (y).\n",
        "\t\tdropnan: Boolean whether or not to drop rows with NaN values.\n",
        "\tReturns:\n",
        "\t\tPandas DataFrame of series framed for supervised learning.\n",
        "\t\"\"\"\n",
        "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
        "\tdf = DataFrame(data)\n",
        "\tcols, names = list(), list()\n",
        "\t# input sequence (t-n, ... t-1)\n",
        "\tfor i in range(n_in, 0, -1):\n",
        "\t\tcols.append(df.shift(i))\n",
        "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# forecast sequence (t, t+1, ... t+n)\n",
        "\tfor i in range(0, n_out):\n",
        "\t\tcols.append(df.shift(-i))\n",
        "\t\tif i == 0:\n",
        "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "\t\telse:\n",
        "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# put it all together\n",
        "\tagg = concat(cols, axis=1)\n",
        "\tagg.columns = names\n",
        "\t# drop rows with NaN values\n",
        "\tif dropnan:\n",
        "\t\tagg.dropna(inplace=True)\n",
        "\treturn agg"
      ],
      "metadata": {
        "id": "UUEzy1KBWfYA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset - y on first column\n",
        "dataset_x = read_csv('../content/sample_data/var_x.csv', header=0, index_col=0)\n",
        "dataset_y = read_csv('../content/sample_data/var_y.csv', header=0, index_col=0)\n",
        "dataset_z = read_csv('../content/sample_data/var_z.csv', header=0, index_col=0)\n",
        "dataset_z = dataset_z.drop(['etc1','etc2','etc3'], 1) # remove columns (1) that won't be used\n",
        "dataset = concat([dataset_y,dataset_x,dataset_z], axis=1)\n",
        "values = dataset.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Xuck4ShWfRg",
        "outputId": "8fbae635-de05-467e-dad0-62cfd98fe687"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# specify columns to plot\n",
        "groups = [0, 1, 2]\n",
        "i = 1\n",
        "# plot each column\n",
        "pyplot.figure()\n",
        "for group in groups:\n",
        "\tpyplot.subplot(len(groups), 1, i)\n",
        "\tpyplot.plot(values[:, group])\n",
        "\tpyplot.title(dataset.columns[group], y=0.5, loc='right')\n",
        "\ti += 1\n",
        "#pyplot.show()\n",
        "pyplot.savefig('series.png')\n",
        "pyplot.close('all')"
      ],
      "metadata": {
        "id": "F_5LtWbpWfO4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize features\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled = scaler.fit_transform(values)\n",
        "# frame as supervised learning\n",
        "reframed = series_to_supervised(scaled, 1, 1)\n",
        "# drop columns we don't want to predict\n",
        "reframed.drop(reframed.columns[[4,5]], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "d5q9xmIaWfMQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split into train and test sets\n",
        "values = reframed.values\n",
        "n_train = -12 # last 12 months to test\n",
        "train, test = values[0:n_train], values[n_train:]\n",
        "# split into input (all columns exceptc last one) and outputs (last column)\n",
        "train_X, train_y = train[:, :-1], train[:, -1]\n",
        "test_X, test_y = test[:, :-1], test[:, -1]\n",
        "# reshape input to be 3D [samples, timesteps, features]; each line turns into an 'sub-array'\n",
        "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
        "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
        "#print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
      ],
      "metadata": {
        "id": "cDgV4ziTWfJI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# design network\n",
        "neurons = 50\n",
        "batch_size = 1\n",
        "epochs = 50\n",
        "model = Sequential()\n",
        "model.add(LSTM(neurons, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mae', optimizer='adam')\n",
        "# fit network\n",
        "history = model.fit(train_X, train_y, epochs=epochs, batch_size=batch_size, validation_data=(test_X, test_y), verbose=0, shuffle=False)\n",
        "# plot history\n",
        "pyplot.clf()\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "#pyplot.show()\n",
        "pyplot.savefig('loss.png')\n",
        "pyplot.close('all')"
      ],
      "metadata": {
        "id": "eYUZMEp2WfAo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a prediction\n",
        "yhat = model.predict(test_X)\n",
        "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
        "# invert scaling for forecast\n",
        "inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
        "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
        "inv_yhat = inv_yhat[:,0]\n",
        "# invert scaling for actual - observed data\n",
        "test_y = test_y.reshape((len(test_y), 1))\n",
        "inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
        "inv_y = scaler.inverse_transform(inv_y)\n",
        "inv_y = inv_y[:,0]\n",
        "# calculate RMSE\n",
        "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
        "print('Test RMSE: %.3f' % rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj6gp4p4W10i",
        "outputId": "435c5b80-70bd-458b-ec16-ff8c397ac5f5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test RMSE: 9105.483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sem enso - Test RMSE: 4452.025\n",
        "\n",
        "# plot baseline and predictions\n",
        "pyplot.clf()\n",
        "pyplot.plot(inv_yhat, label=\"model\")\n",
        "pyplot.plot(inv_y, label=\"observed\")\n",
        "pyplot.legend()\n",
        "#pyplot.show()\n",
        "pyplot.savefig('test_and_train.png')\n",
        "pyplot.close('all')"
      ],
      "metadata": {
        "id": "XpU-zDGJW5Fg"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}